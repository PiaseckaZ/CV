{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1JhZ79eASFvKwH5jglkENNvlouACVX6MS",
      "authorship_tag": "ABX9TyPV/oooJevDRvIQkJEuAGut",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/piaseckazaneta/CV/blob/master/Project1_RiceLeafDiseases.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "import random"
      ],
      "metadata": {
        "id": "1-OorQArPnco"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Loading data"
      ],
      "metadata": {
        "id": "-lQXHrykIMIp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "base_dir = '/content/drive/MyDrive/Project1_RiceLeafDiseases/rice_leaf_diseases'\n",
        "print(os.listdir(base_dir))  # Wyświetla foldery chorób\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UffRaAiwNFh1",
        "outputId": "2da57da7-27f5-4de2-f498-feb3c5a10796"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Leaf smut', 'Brown spot', 'Bacterial leaf blight']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Wczytanie danych przy użyciu image_dataset_from_directory\n",
        "TensorFlow dostarcza funkcji image_dataset_from_directory, która automatycznie wczytuje dane z folderów.\n",
        "\n",
        "a) Wczytanie zbiorów treningowego,walidacyjnego i testowego:"
      ],
      "metadata": {
        "id": "TlOT0rKPN-v_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import image_dataset_from_directory"
      ],
      "metadata": {
        "id": "sQ-Fk7BUNyma"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_yZRNsnJObMB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "b) Utwórz nowe foldery dla podziału danych.\n",
        "\n",
        "Najpierw utwórz foldery dla zbiorów treningowego, walidacyjnego i testowego:"
      ],
      "metadata": {
        "id": "E1e_WjFuPuWl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_dir = '/content/drive/MyDrive/Project1_RiceLeafDiseases/rice_leaf_diseases'  # Ścieżka do folderu z danymi\n",
        "\n",
        "# Ścieżka do folderów docelowych\n",
        "output_dir = '/content/drive/MyDrive/Project1_RiceLeafDiseases/split_data'\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "for split in ['train', 'val', 'test']:\n",
        "    for category in os.listdir(base_dir):\n",
        "        os.makedirs(os.path.join(output_dir, split, category), exist_ok=True)\n"
      ],
      "metadata": {
        "id": "AMewcU9sPlxZ"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "c) Podziel dane na zbiory\n",
        "\n",
        "\n",
        "W tym kroku wybierzesz proporcje podziału (np. 70% danych na trening, 20% na walidację, 10% na test)."
      ],
      "metadata": {
        "id": "hXp_aNRpQVnz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Proporcje podziału\n",
        "train_ratio = 0.7\n",
        "val_ratio = 0.2\n",
        "test_ratio = 0.1\n",
        "\n",
        "# Podział danych\n",
        "for category in os.listdir(base_dir):\n",
        "    category_path = os.path.join(base_dir, category)\n",
        "    images = os.listdir(category_path)\n",
        "    random.shuffle(images)  # Wymieszaj dane losowo\n",
        "\n",
        "    # Oblicz liczbę próbek dla każdego zbioru\n",
        "    train_count = int(len(images) * train_ratio)\n",
        "    val_count = int(len(images) * val_ratio)\n",
        "\n",
        "    # Podziel dane\n",
        "    train_images = images[:train_count]\n",
        "    val_images = images[train_count:train_count + val_count]\n",
        "    test_images = images[train_count + val_count:]\n",
        "\n",
        "    # Przenieś pliki do odpowiednich folderów\n",
        "    for image in train_images:\n",
        "        shutil.copy(os.path.join(category_path, image),\n",
        "                    os.path.join(output_dir, 'train', category, image))\n",
        "\n",
        "    for image in val_images:\n",
        "        shutil.copy(os.path.join(category_path, image),\n",
        "                    os.path.join(output_dir, 'val', category, image))\n",
        "\n",
        "    for image in test_images:\n",
        "        shutil.copy(os.path.join(category_path, image),\n",
        "                    os.path.join(output_dir, 'test', category, image))\n",
        "\n",
        "print(\"Dane zostały podzielone!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WbtfEqpsQYDQ",
        "outputId": "82771ff6-129b-4d9f-daae-6c72532d56ae"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dane zostały podzielone!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Zweryfikuj podział\n",
        "\n",
        "Po wykonaniu podziału możesz sprawdzić, czy dane zostały poprawnie przeniesione:"
      ],
      "metadata": {
        "id": "IYTP9QcPRJ_l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Liczba obrazów w każdym zbiorze\n",
        "for split in ['train', 'val', 'test']:\n",
        "    for category in os.listdir(base_dir):\n",
        "        split_dir = os.path.join(output_dir, split, category)\n",
        "        print(f\"{split}/{category}: {len(os.listdir(split_dir))} obrazów\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x3ysm34cRLZr",
        "outputId": "db5baeb1-9acb-44ab-97a5-224a8bf7f68e"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train/Leaf smut: 28 obrazów\n",
            "train/Brown spot: 28 obrazów\n",
            "train/Bacterial leaf blight: 28 obrazów\n",
            "val/Leaf smut: 8 obrazów\n",
            "val/Brown spot: 8 obrazów\n",
            "val/Bacterial leaf blight: 8 obrazów\n",
            "test/Leaf smut: 4 obrazów\n",
            "test/Brown spot: 4 obrazów\n",
            "test/Bacterial leaf blight: 4 obrazów\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Wczytaj dane do TensorFlow\n",
        "\n",
        "Teraz możesz wczytać dane podzielone na zbiory przy użyciu image_dataset_from_directory:"
      ],
      "metadata": {
        "id": "yuzQ_SE6RZ4f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import image_dataset_from_directory\n",
        "\n",
        "data_dir = '/content/drive/MyDrive/Project1_RiceLeafDiseases/split_data'\n",
        "\n",
        "# Wczytaj dane treningowe, walidacyjne i testowe\n",
        "train_ds = image_dataset_from_directory(\n",
        "    os.path.join(data_dir, 'train'),\n",
        "    image_size=(224, 224),\n",
        "    batch_size=32\n",
        ")\n",
        "\n",
        "val_ds = image_dataset_from_directory(\n",
        "    os.path.join(data_dir, 'val'),\n",
        "    image_size=(224, 224),\n",
        "    batch_size=32\n",
        ")\n",
        "\n",
        "test_ds = image_dataset_from_directory(\n",
        "    os.path.join(data_dir, 'test'),\n",
        "    image_size=(224, 224),\n",
        "    batch_size=32\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DYwnZ9XKRbot",
        "outputId": "3dbac091-7f91-4b53-f402-7daf7e1b68c5"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 84 files belonging to 3 classes.\n",
            "Found 24 files belonging to 3 classes.\n",
            "Found 12 files belonging to 3 classes.\n"
          ]
        }
      ]
    }
  ]
}